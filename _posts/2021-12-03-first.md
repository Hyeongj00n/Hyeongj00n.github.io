---
layout: single
title:  "AI:X 딥러닝 Final project"
---

- ***Who am I***
  - 자기소개

- ***I. 인트로***
  - I-1. AI란?
  - I-2. 머신러닝이란?

- ***II. About Random Forest***
  - 알고리즘의 역사
  - 알고리즘의 원리
  - 알고리즘 설명
  - 알고리즘 적용범위 

- ***III. 정리***
- ***IV. 엔딩***



#  WHO AM I
___

현재 한양대학교 경영학부에 재학중인 우형준입니다.  상경계열이라고는 하나, 순도 100% 문돌이인 제가 어쩌다 Tech blog인 GITHUB에 글을 쓰게 되었는지... 요즘 내 네이버 블로그도 못올리고 있는데..코딩에 대해서 아는거라곤, 1학년때  '창의적 컴퓨팅'이라는 수업에서 맛만보았던 파이썬 정도...? 

기억나는 파이썬 문법이라곤 
``` python
print('hello world!')
```

정도만 기억나네요. 각설하고 현재 수강중인 AI:X딥러닝 수업의 Final project과제 때문에 이렇게 글을 작성하게 되었습니다. 아무것도 모르는 나에게 설명한다는 느낌으로, 천천히 차근차근 작성해보도록 하겠습니다.

아래 이미지는, 깃허브 포스팅에 이미지 삽입연습할겸 넣어보았습니다
<p align="center">
  <img src= "https://user-images.githubusercontent.com/95233589/145932593-dc690c60-f96c-4d8d-b73a-94fccde9c700.jpg" width="400" height="400"/>
</p>

# I. 인트로
## I-1.AI란?  

블로그를 만들고, 글을 작성하게 된 이유가 현재 수강중인 AI:X 딥러닝 수업 때문입니다. 따라서 Random Forest에 대한 이해에 앞서서, AI와 머신러닝에 대한 설명을 먼저 하려합니다. AI는 워낙 많은 곳에서 들려오니까 많이들 들어 보셨을 거 같습니다. 영화에서도 많이 보이고, 이제는 얼마전이라고 하기엔 좀 멀지만, 2016년 우리나라에서 화제가 되었던 바둑 인공지능 프로그램 알파고 또한 AI입니다. 우리의 생활과도 밀접한 관계에 있는 빅스비, 시리 등도 AI를 활용한 프로그램 중 하나입니다.  
![HER 한장면](https://user-images.githubusercontent.com/95233589/146167818-9ba85ff4-ee3b-406f-9e4d-8028a09295ab.jpg)
> 인공지능 음성비서 '사만다' 와 사랑에 빠진 남자의 이야기를 다룬 영화 'HER'

이렇게 다양한 매체에서, 다양한 방법으로 활용되고 있는 AI의 정의를 살펴보면
> “인간의 학습능력, 추론능력, 지각능력을 인공적으로 구현하려는 컴퓨터과학의 세부분야이다.”(from wikipedia)

라고 되어있습니다. 사람이 내리는 결정을, 컴퓨터가 대신 사람과 유사하게 만드는 것이라고 생각합니다. 
![AIX1](https://user-images.githubusercontent.com/95233589/146167467-9e6aade0-7de7-49eb-a27b-2963a5ba6513.JPG)

사람과 유사하게 컴퓨터가 결정을 내린다면, 두가지 분류가 가능할 것으로 생각됩니다.    

| 인공지능 분류 |
|:---|
| 1) 결과값만 사람과 똑같이 나오는 인공지능 |  
| 2) 결과값이 도출되는 과정도 사람과 똑같은 인공지능 |  

이렇게 두가지의 인공지능이 존재한다면, 딱 봐도 2번째 인공지능이 더 어려운 기술일것으로 고려됩니다. 인간과 과정도 똑같다면 우선적으로, 인간이 왜 그런 결정을 내렸는가에 대한 이해가 선행되어야 하는데… 살면서 계속 하는 결정에서 내 스스로도 왜 그런결정을 내렸을까? 라고 의문이드는 결정 투성이인데, 그 과정을 완벽히 이해하고 기계 혹은 컴퓨터에게 알려주는 과정은 쉽지 않을 것이라고 생각됩니다. 

딴소리가 많았는데, 결국 인공지능은 사람의 지능을 활용한 결정능력을 컴퓨터가 유사 혹은 동일하게 할 수 있도록 만드는 기술이라고 정리할 수 있을 것 같습니다. 

## I-2. 머신러닝이란?
인공지능에 대한 이야기를하면, 머신러닝 즉 기계학습에 대한 이야기가 빠질 수 없을 것 같습니다. 인공지능, 머신러닝, 딥러닝의 관계를 그리면
![AIX2](https://user-images.githubusercontent.com/95233589/146169633-19391a3d-dec0-42b0-99d3-b71fa037296b.JPG)  

이렇게 됩니다. 인공지능 기술 분야안에, 머신러닝이 존재하고, 머신러닝 분야안에 딥러닝이 존재합니다. 

**학습!**  

고등학교 2학년 때, 담임선생님께서 자주 하셨던 말씀이였습니다. 학습의 뜻을 봐라, **배울 學(학) 익힐 習(습)**, 너네가 학원가고 학교에서 강의 듣는거는 50% 學(학) 밖에 하지 않는거다. 스스로 다시 그걸 익히는 시간인 習(습)을 가져야지만 100% 공부가 되는거다. 이 의미는, 습이라는 시간을 통해, 배운 것 그 이상으로 새로운 output을 낼 수 있도록 노력하라는 뜻이였습니다.  
아마 기계학습도 이와 비슷하게, 무언가 input이 되었을 때, 어떠한 방법으로 input이상의 새로운 output을 내는 것이라고 생각이 듭니다. 정의를 살펴보면

>“경험을 통해 자동으로 개선하는 컴퓨터 알고리즘의 연구이다.” (from wikipedia)

좀 말이 모호한데, 일상생활에 있는 기계학습을 보면, 좀 더 이해가 쉬울 것 같습니다. 넷플릭스 사용할 때 보면 @@님이 좋아할만한 컨텐츠! 라며 컨텐츠 추천이 이루어집니다.  

![AIX5](https://user-images.githubusercontent.com/95233589/146169938-9ba5267e-df95-483b-9711-1bba14e42112.jpg)
> 넷플릭스에 있는 추천 콘텐츠

이렇게 우리에게 추천해주는 컨텐츠가 머신러닝을 활용한 분야입니다. 넷플릭스의 추천 알고리즘은, 데이터들을 바탕으로 패턴 즉 규칙을 파악합니다. 그 패턴을 바탕으로, 제가 좋아할 만한 컨텐츠를 추천해줍니다. 머신러닝이 없이 추천을 한다면, A란 영화를 본 사람에게는 무조건 B를 추천해라 라는 명령을 바탕으로, A를 본사람의 취향과 관계없이 B를 추천할 것입니다. 하지만 머신러닝을 활용한다면, A를 본사람에게 그 사람이 좋아할만한 컨텐츠를 추천해라! 라는 명령이 들어갈 것이고, 컴퓨터는, A를 본 다른 사람들은 무슨 컨텐츠를 좋아하지? 같은 규칙을 파악한뒤 알맞은 컨텐츠를 추천해줄 것입니다.
![AIX3](https://user-images.githubusercontent.com/95233589/146170031-c368ea17-a251-41bf-9982-9c6dea763d60.JPG)

사람과 비슷한 느낌의 결정이라고 생각이 듭니다. 보통 친구가 나 영화 추천해줘 라고 물어볼 때, 그럼 A는 어때? 라고 바로 묻기보다는, 너 무슨 장르 좋아해? 배우는? 국내? 해외? 등 질문을 통해 친구가 좋아할만한 영화를 예측하듯이 넷플릭스의 머신러닝도 사용자들에게 직접 묻지는 못해도, 그 사람들의 시청기록을 바탕으로 나름대로의 결론을 내고, 그 결론에 맞추어 추천하는 것입니다.    

| 인공지능 분류 |
|:---|
| 1) 결과값만 사람과 똑같이 나오는 인공지능 |  
| 2) 결과값이 도출되는 과정도 사람과 똑같은 인공지능 |    

앞에서 언급한, 두가지의 인공지능 분류 중 두번째에 가까워지는 듯한 느낌이 듭니다. 하지만, 여전히 아 느낌이 너 이거 좋아할 듯? 같은 직관적인 느낌의 추천은 힘들어 보입니다.   

---
머신러닝은, 풀고자 하는 목표에 따라서 크게 세가지로 구분이 됩니다. 
**지도학습, 비지도학습, 강화학습**

개인적인 생각일지 모르지만, 머신러닝 이라고 했을 때, 떠오르는 모양은 지도학습의 모양이였습니다. 지도학습은 데이터와, 정답을 학습시킨 뒤 새로운 데이터를 입력하여 그 데이터의 정답을 찾도록 만드는 것입니다. 즉 규칙을 데이터와 정답을 통해 발견하도록 하여, 앞으로 들어올 새로운 데이터들의 정답을 규칙으로 발견하도록 하는 것입니다. 이러한 규칙은 보통 함수로 표현됩니다. 

![AIX6](https://user-images.githubusercontent.com/95233589/146208995-c57b2bb2-1e59-4127-8c48-4b1a76e71146.JPG)  

이렇게 구조로 보면, 보통 우리가 학습하는 방식과 비슷해 보입니다. 문제와 정답을 미리 배우고, 그 후 새로운 문제를 기존의 문제로 익힌 방법으로 풀어 나가는? 그래서 개인적으로 지도학습의 모양이 가장 먼저 떠올랐는지도 모르겠습니다.   
**지도학습**은 분류, 회귀에 사용됩니다. 분류는 말 그대로, 입력된 데이터가 어디에 속하는지 구분하는 것이며, 회귀란 단어가 생소한데, 데이터의 특징을 바탕으로 결과값을 예측하는 것입니다. 트렌드 예측, 특정 가격 예측처럼 과거의 결과들의 상관관계를 알아내어 미래의 값을 예측하는 것입니다. 회귀에 특징이라는 단어가 들어가는데, 이 특징을 머신러닝에서는 Feature라고 부릅니다.  
**Feature** 또한 머신러닝에서 굉장히 중요한 요소입니다. 예를 들어 영화의 장르를 구분하는 머신러닝을 만들고 싶을 때,  
**‘영화에 키스신이 4번이상 들어가면 로맨스 영화로 분류해’** 라고 말하는 것과,  
**‘영화가 한시간이 넘으면 로맨스 영화로 분류해’** 라고 하는것중 정확도가 더 높은건 뭘까요?  
아마 당연히 전자일겁니다. 후자 같은 경우는 대부분의 영화가 로맨스 영화로 분류가 되고 잘못된 결과를 도출할 가능성이 높습니다. 잘못된 Feature는 완전히 잘못된 결과를 가져올 수 있습니다. 그러므로 Feature를 잘 뽑아내서 설계하는 능력도 중요합니다. 

제가 소개할 알고리즘인 Random Forest는, 머신러닝의 지도학습 알고리즘 중 하나입니다. 
  
  
# II. About Random forest
Random Forest가 지도학습 알고리즘 중 하나라고 말했기 때문에, 이 알고리즘은 분류, 회귀에 사용하기에 적합한 형태의 알고리즘이라고 예상할 수 있습니다. 이름을 보면 Random과 Forest가 들어가있는데, 먼저 Forest의 뜻을 알아보겠습니다. 나무들이 모여 숲을 이루듯이, Random Forest는 Decision Tree 여러 개가 구성하고 있기 때문에 Forest란 이름이 붙었습니다. 그렇다면 Decesion Tree는 무엇일까요?  

![AIX10](https://user-images.githubusercontent.com/95233589/146218353-c320faf0-0b33-4184-b3bd-dd25ebfae5e7.JPG)

### II-1. Decision Tree 의사결정 나무
Decision Tree는, 스무고개를 생각하면 쉽습니다. 꼬리에 꼬리를 무는 질문처럼, 계속해서 질문을 통해 결과를 내는 것입니다.  
![AIX7](https://user-images.githubusercontent.com/95233589/146218427-d7ae4b33-3c85-4ba1-a5fd-95cc9de113b4.JPG)  
![AIX8](https://user-images.githubusercontent.com/95233589/146218504-497aba63-44e4-4283-8fd0-8f3b7f25ce74.JPG)  

이런 스무고개의 모양에서 시작하는 질문을 Root node(뿌리마디), 중간에 있는 질문을 Intermediate node(중간마디), 정답, 마지막 부분을 Terminal node(끝마디) 라고 합니다.    
위 사진의 Decesion Tree로 학습된 프로그램에 **Test data(테스트 데이터)인 [A : 동물 아님, 움직이지 못함]** 을 집어넣는다면, 결과값은 무엇으로 나올까요? 
동물이 아니기 때문에 첫번째 intermediate node로 질문이 넘어가고, 그 질문에서 '아니요'라고 답하기 때문에 A는 **의자** 라고 결과가 나올 것입니다.  
Decesion Tree는 지도학습이기 때문에 우리는 A의 정답 또한 알고 있습니다. 그러므로 A가 진짜로 의자라면, 이 Decesion tree는 나름 정확하다고 볼 수 있습니다.  
이런식으로 Training data로 질문들을 만든 후, Test data로 이 Decesion tree가 정말로 잘 작동하는지 확인할 수 있습니다.  

Decesion Tree의 이름은, 알고리즘의 특성과 구조의 모양으로 이름이 결정되었습니다.  
![AI9](https://user-images.githubusercontent.com/95233589/146218594-d5b0d798-b005-48f6-9335-c3b7832cb1e4.JPG)  
이런 구조 형식을 뒤집으면 나무처럼 생겼다고 해서 Decision Tree라고 불립니다. 
**Decision Tree**의 프로세스는 아래 이미지처럼 이루어집니다.  

![알고리즘 1](https://user-images.githubusercontent.com/95233589/146218719-06663bf1-c0e3-4569-8b0c-ddea67d33b4b.png)  
#### 출처 : 텐서플로우 블로그  
![알고리즘2](https://user-images.githubusercontent.com/95233589/146219109-cc4ed293-da85-449d-a86f-9c4e53e9ea68.png)  
#### 출처 : 텐서플로우 블로그  
![알고리즘3](https://user-images.githubusercontent.com/95233589/146219188-b61f8092-eedb-46d1-b875-077189d8b2e9.png)  
#### 출처 : 텐서플로우 블로그  
그렇다면 Intermediate node가 많아질수록 무조건 정확한 결과가 나올까요?  
**정답은 X**입니다.  
오히려 Intermediate node가 계속해서 많아지고, 학습이 너무 과하게 진행된다면 overfitting(과적합)이 나타납니다. 예를 들어 나는 동물을 포유류, 양서류 등으로 구분하고 싶은데 계속해서 스무고개가 진행된다면 동물 개체 하나하나로 구분이 될 것입니다. 이는 내가 원하는 결과와 학습한 결과가 달라지기에 조절이 필요해 보입니다. 따라서 과적합이 이루어지지 않도록 하는 과정이 필요한데, 이를 **가지치기**라고 합니다. 가지치기는 여러가지 방법으로 가능합니다. Decision tree자체에서 질문을 몇번 할것이냐? 즉 깊이를 몇으로 설정할 것이냐, 한 node에서 뻗어나는 가지의 개수를 조절하거나, Terminal node의 개수를 설정하는 방법 등 여러가지 방법이 있습니다.   
Decision tree에만 적용되는건 아니지만, 과적합을 방지하는 또 다른 방법중 하나는 **‘Ensemble’(앙상블)학습법** 입니다. 제가 소개하는 Random Forest가 앙상블을 활용한 가장 유명한 방법 중 하나입니다.   
  
### II-2. Ensemble(앙상블)
앙상블은 여러 개의 알고리즘을 활용하여, 보다 정확한 예측을 도출하는 방법입니다. 여러개의 알고리즘이라는 단어에서, 눈치챌 수 있지만 Random Forest 는 Decision tree 라는 여러 개의 알고리즘을 활용하여, 앙상블 학습을 하는 방법 중 하나입니다.  
앙상블학습은 **보팅(Voting), 배깅(Bagging), 부스팅(Boosting)** 이라는 대표적인 유형으로 나눌 수 있습니다.     
**보팅**은 한가지 데이터를 사용해 여러가지의 알고리즘으로 각각의 결과에 대해 투표를 하여 최종 결과를 예측하는 것입니다.  
##### <보팅 프로세스>   
![AIX11](https://user-images.githubusercontent.com/95233589/146235088-0b78a4ed-174b-4b4e-aee6-0e53e60a8106.JPG)    
     
**배깅**은 서로 다른 데이터를 사용해 한가지의 알고리즘으로, 결과에 대해 투표를 하여 최종 결과를 예측하는 것입니다.  
##### <배깅 프로세스>    
![AIX12](https://user-images.githubusercontent.com/95233589/146235187-aa21beb6-15ea-488e-9d96-db0d935e3f72.JPG)      
       
**부스팅**은 여러 개의 알고리즘을 활용하여, 순차적으로 학습을 진행하는 것이다. 첫번째 알고리즘의 결과값에서 가중치를 적용하여 더 정확하게 만들어 다음 알고리즘에 진행, 이런식으로 결과값에 가중치를 추가하여 결과를 예측하는 것입니다.  
##### <부스팅 프로세스>  
![AIX13](https://user-images.githubusercontent.com/95233589/146235327-4438336e-8210-4f4c-9118-36c181b811d4.JPG)    
   
셋의 차이를 표로 나타내보면  

| 이름 | Traing Data | 알고리즘 종류 |
|:---:|:---:|:---:|
| 보팅 | 한가지 | 여러개 
| 배깅 | 여러개 | 한가지
| 부스팅 | 한가지 | 여러개

이렇게 방법을 봤을 때 Random forest는 무슨 앙상블 방법을 사용하는 걸까요?  
Decision tree 하나의 알고리즘만 사용하기 때문에 딱봐도 배깅이라는 것을 알 수 있습니다. 또한 배깅이라는 방법에서 Random의 의미를 파악할 수 있습니다. 배깅이 서로 다른 데이터를 통해 사용하는 방법, 서로 다른 데이터에서 **Random** 이 등장합니다. 서로 다른 데이터를 무작위로 뽑아내기 때문입니다. 예를들어 500개가 담겨있는 Training data에서, 100개씩 무작위로 뽑아서 traing data로 활용하는 것입니다. 이때 뽑아내는 data는 중복이 가능합니다.  
![AIX16](https://user-images.githubusercontent.com/95233589/146241969-000f3ab3-4d7f-4fc3-bfa0-950e2eab9c77.JPG)  

그러고 보니 프로세스에 있는 보팅에 대해 언급을 안했었는데, 프로세스에 있는 보팅은 말 그대로 투표라고 생각하면 됩니다. 각 Decesion tree의 결과값들을 보고, 그 결과값중 가장 많이 나온 결과값을 결과값으로 도출합니다.  
만약 Random forest를 분류로 사용한다면 평균값을 사용하기도 합니다.  

![AIX15](https://user-images.githubusercontent.com/95233589/146242001-55737c0f-7aea-4d18-84c2-c93e0ec26eab.JPG)  

### 이렇게 Random으로 뽑은 데이터를 여러 개의 Decision tree(Forest)를 활용해서 결과를 내는 것이 바로 Random Forest입니다. 


이렇게 좋은 머신러닝 방법중 하나인 **Random Forest** 는 파이썬에서 사용이 가능합니다. 












